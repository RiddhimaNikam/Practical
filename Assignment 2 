{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import models, layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=200)\n",
    "X_test = pad_sequences(X_test, maxlen=200)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - accuracy: 0.6886 - loss: 0.5604 - val_accuracy: 0.7924 - val_loss: 0.4606\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.8568 - loss: 0.3514 - val_accuracy: 0.8292 - val_loss: 0.4045\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8526 - loss: 0.3447 - val_accuracy: 0.8060 - val_loss: 0.4359\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.8705 - loss: 0.3084 - val_accuracy: 0.8486 - val_loss: 0.3766\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.8807 - loss: 0.2877 - val_accuracy: 0.8432 - val_loss: 0.3783\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.9206 - loss: 0.2053 - val_accuracy: 0.8400 - val_loss: 0.3912\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9354 - loss: 0.1726 - val_accuracy: 0.8592 - val_loss: 0.4065\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9544 - loss: 0.1322 - val_accuracy: 0.8538 - val_loss: 0.4711\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.9628 - loss: 0.1068 - val_accuracy: 0.8476 - val_loss: 0.4909\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.9728 - loss: 0.0792 - val_accuracy: 0.8352 - val_loss: 0.5134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x251b3ba8bf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=10000, output_dim=128))\n",
    "    model.add(layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8368 - loss: 0.5180\n",
      "Accuracy: 83.95%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Review 1: \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? the most enjoyable pet movie since scooby doo and garfield the story revolves around a 23 year old ? named brian foster whose systems at his ? company seems to keep failing brian is also dating the ? daughter named ? but brian secretly invented a robotic dog named ? ? after his own dog ? but ? is no ? dog he is as fast as a ? he has x ray vision can leap about 6 feet and has a strength of 20 men the new invention ? his boss and makes his business a success but when the company rivals hear about ? they try to find a way to capture him can ? ? them before its too late this movie is a classic for all ages\"\n",
      "Predicted Sentiment: Positive\n",
      "Actual Sentiment: Positive\n",
      "\n",
      "Review 2: \"? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? this satire is just really really dead on and nobody is ? but even though this movie has plenty of laughs within the silly story and the grotesque imitation of hitler here cleverly ? as and speaking in a hilarious kind of pseudo german the general tone is pretty sad maybe because of the movie's place in history and the actors aren't even ? that much i suppose one of the greatest movie moments of all time must be the jewish ending speech if only things could have ended in that way it's not even really the character talking anymore it's chaplin saying something he really wanted to say if you ignore the technical aspects the movie doesn't feel dated or old it actually moves at a pretty nice pace and the sharp humor we find everywhere in this work will never die the only thing i don't care for is the slapstick but that just comes with the era i suppose this is an incredibly daring harsh take on ? it's so hard hitting still after all these years\"\n",
      "Predicted Sentiment: Negative\n",
      "Actual Sentiment: Positive\n",
      "\n",
      "Review 3: \"out on his mission or ? to fight tooth ? in the back and of ? from northern ireland via new jersey the main character sees his ? as a mission of mass importance and approaches it with all the enthusiasm ? discipline and attention to detail one would expect from a trained dentist which adds to the hilarity as his grand plans unravel and gradually fall to pieces as he goes from disaster to ? in the ? on the back of a ? ? bike or his er mobile dental unit we never get to meet his wife nor the rich ? who is ? the ill ? mission but we do get a solid display from lewis fans of his work will not be disappointed with his very believable performance as the ? dentist who is ? by the innocent but sexy 18 year old female lead who ? along on for the ? ride br br this film is not for everyone and i can understand why it wasn't pushed by the suits it's a low budget sometimes charming always ? mildly amusing and instantly forgettable film that sets out with low expectations and almost succeeds\"\n",
      "Predicted Sentiment: Positive\n",
      "Actual Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "sample_reviews = [decode_review(X_test[i]) for i in random.sample(range(len(X_test)), 3)]\n",
    "preprocessed_reviews = pad_sequences([[word_index.get(word, 0) for word in review.split()] for review in sample_reviews], maxlen=200)\n",
    "\n",
    "predictions = model.predict(preprocessed_reviews)\n",
    "\n",
    "for i, (review, prediction, actual) in enumerate(zip(sample_reviews, predictions, [y_test[i] for i in random.sample(range(len(X_test)), 3)])):\n",
    "    print(f'Review {i+1}: \\\"{review}\\\"\\nPredicted Sentiment: {'Positive' if prediction > 0.5 else 'Negative'}\\nActual Sentiment: {'Positive' if actual == 1 else 'Negative'}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
